# Phase 3 - Next Steps & Continuation Guide

**Last Updated**: October 22, 2025  
**Current Status**: üü° IN PROGRESS (Core implementation complete)  
**Estimated Remaining**: 2.5 days

---

## Overview

Phase 3 core components are complete and tested. The remaining work focuses on:
1. **Storage Integration** (MinIO + TimescaleDB)
2. **End-to-End Testing**
3. **Performance Validation**
4. **Production Hardening**

---

## Immediate Next Tasks (Order of Priority)

### Task A: Implement MinIO Storage Integration (4-6 hours)
**Location**: `src/tasks/acquire_iq.py` - `save_measurements_to_minio()` function

#### What to Implement
```python
@shared_task(bind=True)
def save_measurements_to_minio(self, task_id: str, measurements: List[Dict]):
    """
    Save IQ data arrays to MinIO S3 storage.
    
    Implementation checklist:
    1. Initialize boto3 S3 client with MinIO endpoint
    2. For each measurement:
       a. Extract IQ data array from measurement['iq_data']
       b. Save to .npy file with numpy
       c. Create metadata JSON
       d. Upload to MinIO: s3://heimdall-raw-iq/sessions/{task_id}/websdr_{id}.npy
    3. Return success/failure summary
    
    Error handling:
    - Connection errors: retry with backoff
    - Out of storage: raise clear error
    - Invalid data: skip with logging
    """
```

#### Code Pattern to Follow
```python
import boto3
from ..config import settings

# Client initialization
s3_client = boto3.client(
    's3',
    endpoint_url=settings.minio_url,
    aws_access_key_id=settings.minio_access_key,
    aws_secret_access_key=settings.minio_secret_key,
    region_name='us-east-1'
)

# Upload example
s3_client.put_object(
    Bucket=settings.minio_bucket_raw_iq,
    Key=f'sessions/{task_id}/websdr_{websdr_id}.npy',
    Body=iq_npy_bytes,
    Metadata={'frequency_mhz': str(frequency_mhz)}
)
```

#### Tests to Add
- Test MinIO connection
- Test upload of .npy file
- Test metadata storage
- Test retrieval

#### Files to Modify
- `src/tasks/acquire_iq.py` - implement `save_measurements_to_minio`
- `tests/integration/test_minio_storage.py` - new test file
- `src/config.py` - verify MinIO env vars

#### Estimated Time: **4-6 hours**

---

### Task B: Implement TimescaleDB Integration (4-6 hours)
**Location**: New files in `src/` and `db/migrations/`

#### What to Implement
1. **Database Migration** (`db/migrations/001_create_measurements_table.sql`)
   ```sql
   CREATE TABLE IF NOT EXISTS measurements (
       id BIGSERIAL PRIMARY KEY,
       task_id UUID NOT NULL,
       websdr_id INT NOT NULL,
       frequency_mhz FLOAT NOT NULL,
       sample_rate_khz FLOAT NOT NULL,
       samples_count INT NOT NULL,
       timestamp_utc TIMESTAMPTZ NOT NULL,
       
       -- Metrics
       snr_db FLOAT NOT NULL,
       psd_dbm FLOAT NOT NULL,
       frequency_offset_hz FLOAT NOT NULL,
       signal_power_dbm FLOAT NOT NULL,
       noise_power_dbm FLOAT NOT NULL,
       
       -- Storage path
       iq_data_path VARCHAR NOT NULL,
       metadata_json JSONB,
       
       -- Metadata
       created_at TIMESTAMPTZ DEFAULT NOW(),
       FOREIGN KEY (websdr_id) REFERENCES websdrs(id)
   );
   
   -- Create hypertable for time-series optimization
   SELECT create_hypertable('measurements', 'timestamp_utc', if_not_exists => TRUE);
   
   -- Create indexes for common queries
   CREATE INDEX ON measurements (task_id, timestamp_utc DESC);
   CREATE INDEX ON measurements (websdr_id, timestamp_utc DESC);
   CREATE INDEX ON measurements (frequency_mhz);
   ```

2. **SQLAlchemy Model** (`src/models/db.py`)
   ```python
   from sqlalchemy import Column, Integer, Float, String, DateTime, JSON, ForeignKey
   from sqlalchemy.dialects.postgresql import UUID
   from datetime import datetime
   
   class Measurement(Base):
       __tablename__ = "measurements"
       
       id = Column(BigInteger, primary_key=True)
       task_id = Column(UUID, nullable=False, index=True)
       websdr_id = Column(Integer, ForeignKey('websdrs.id'), nullable=False)
       frequency_mhz = Column(Float, nullable=False)
       sample_rate_khz = Column(Float, nullable=False)
       samples_count = Column(Integer, nullable=False)
       timestamp_utc = Column(DateTime(timezone=True), nullable=False, index=True)
       
       snr_db = Column(Float, nullable=False)
       psd_dbm = Column(Float, nullable=False)
       frequency_offset_hz = Column(Float, nullable=False)
       signal_power_dbm = Column(Float, nullable=False)
       noise_power_dbm = Column(Float, nullable=False)
       
       iq_data_path = Column(String, nullable=False)
       metadata_json = Column(JSON)
       created_at = Column(DateTime(timezone=True), default=datetime.utcnow)
   ```

3. **Celery Task** (`src/tasks/acquire_iq.py`)
   ```python
   @shared_task(bind=True)
   def save_measurements_to_timescaledb(self, task_id: str, measurements: List[Dict]):
       """Bulk insert measurements into TimescaleDB hypertable"""
       # Implementation details:
       # - Use SQLAlchemy session
       # - Bulk insert for performance
       # - Handle duplicates gracefully
       # - Return insertion count
   ```

#### Tests to Add
- Test table creation
- Test bulk insert
- Test hypertable query performance
- Test index usage
- Test time-range queries

#### Files to Modify/Create
- `db/migrations/001_create_measurements_table.sql` - new migration
- `src/models/db.py` - new SQLAlchemy models
- `src/tasks/acquire_iq.py` - implement `save_measurements_to_timescaledb`
- `tests/integration/test_timescaledb_storage.py` - new test file

#### Estimated Time: **4-6 hours**

---

### Task C: WebSDR Configuration from Database (2-3 hours)
**Location**: `src/routers/acquisition.py`

#### What to Implement
Current implementation uses hardcoded configs in `DEFAULT_WEBSDRS`. Change to:

```python
async def get_websdrs_config() -> list[dict]:
    """Load WebSDR configs from database instead of hardcoded list"""
    
    # Connect to PostgreSQL
    # SELECT * FROM websdrs WHERE is_active = TRUE
    # Return as list of dicts
    
    db_session = Session()
    websdrs = db_session.query(WebSDRModel).filter_by(is_active=True).all()
    return [ws.to_dict() for ws in websdrs]
```

#### Create WebSDRs Table
```sql
CREATE TABLE IF NOT EXISTS websdrs (
    id SERIAL PRIMARY KEY,
    name VARCHAR UNIQUE NOT NULL,
    url VARCHAR NOT NULL,
    location_name VARCHAR,
    latitude FLOAT NOT NULL,
    longitude FLOAT NOT NULL,
    is_active BOOLEAN DEFAULT TRUE,
    timeout_seconds INT DEFAULT 30,
    retry_count INT DEFAULT 3,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Pre-populate with 7 default receivers
INSERT INTO websdrs (id, name, url, location_name, latitude, longitude) VALUES
(1, 'F5LEN Toulouse', 'http://websdr.f5len.net:8901', 'Toulouse, France', 43.5, 1.4),
(2, 'PH0M Pachmarke', 'http://websdr.pa3weg.nl:8901', 'Pachmarke, Netherlands', 52.5, 4.8),
-- ... etc
```

#### Estimated Time: **2-3 hours**

---

### Task D: End-to-End Integration Test (4-5 hours)
**Location**: `tests/integration/test_e2e_acquisition.py`

#### What to Test
```python
@pytest.mark.asyncio
async def test_full_acquisition_workflow():
    """
    Full acquisition flow:
    1. Trigger acquisition via HTTP
    2. Celery task fetches from mocked WebSDRs
    3. Metrics computed and stored in memory
    4. Save to MinIO (mocked)
    5. Save to TimescaleDB (mocked or real)
    6. Poll status and verify completion
    7. Verify data in storage
    """
```

#### Test Scenarios
- Successful acquisition from all 7 receivers
- Partial failure (3/7 succeed)
- Timeout handling
- Invalid parameters
- Status polling progression (0% ‚Üí 50% ‚Üí 100%)
- Measurement data validation
- Error message propagation

#### Estimated Time: **4-5 hours**

---

### Task E: Performance Validation (3-4 hours)
**Location**: `tests/performance/` (new directory)

#### What to Validate
```python
def test_acquisition_latency():
    """Measure end-to-end latency"""
    # Target: <5 seconds for 7 simultaneous acquisitions
    # Target: <500ms per measurement processing
    
    start = time.time()
    results = acquire_iq(frequency_mhz=145.5, duration_seconds=10, ...)
    elapsed = time.time() - start
    
    assert elapsed < 5.0, f"Total time: {elapsed}s (target: <5s)"
```

#### Benchmarks to Establish
- Fetch latency per receiver
- Processing latency per measurement
- MinIO upload latency
- DB insert latency
- Total end-to-end latency

#### Files to Create
- `tests/performance/test_latency.py`
- `tests/performance/benchmark_results.md`

#### Estimated Time: **3-4 hours**

---

## Parallel Work That Can Happen

### Task F: Documentation (2-3 hours)
- API endpoint documentation improvements
- Architecture diagrams with Mermaid
- Deployment guide
- Troubleshooting guide

**Can be done in parallel with Tasks A-E**

### Task G: Error Recovery Tests (2-3 hours)
- Network disconnection handling
- Partial failure recovery
- Celery worker crash handling
- Database connection loss

**Can be done after Task D**

---

## Dependencies & Blockers

### Before Starting Task A (MinIO):
- ‚úÖ MinIO container running in docker-compose
- ‚úÖ boto3 in requirements.txt
- ‚úÖ Environment variables configured (.env file)

### Before Starting Task B (TimescaleDB):
- ‚úÖ PostgreSQL/TimescaleDB running
- ‚úÖ Alembic setup for migrations
- ‚úÖ SQLAlchemy models infrastructure

### Before Starting Task C (WebSDR DB):
- ‚úÖ Requires WebSDRs table (create during Task B or separately)

### Before Starting Task D (E2E Testing):
- ‚úÖ Tasks A and B should be mostly complete
- ‚ö†Ô∏è Can mock storage systems if needed

---

## Execution Timeline

### Option 1: Sequential (5-7 days)
```
Day 1: Task A (MinIO storage)
Day 2: Task B (TimescaleDB storage)
Day 3: Task C (WebSDR config from DB)
Day 4: Task D (End-to-end test)
Day 5: Task E (Performance validation)
```

### Option 2: Parallel (2-3 days)
```
Day 1 AM: Task A start
Day 1 PM: Task B start (parallel with A)
Day 2 AM: Complete A & B, start C
Day 2 PM: Complete C, start D
Day 3 AM: Complete D, start E
Day 3 PM: Complete E
```

### Current Recommendation: Option 2 (Parallel)
- Maximize efficiency
- Unblock Phase 4 sooner
- Less risk of context loss

---

## Testing Strategy

### Unit Tests (per task)
```bash
# After Task A
pytest tests/unit/test_minio_storage.py -v

# After Task B
pytest tests/unit/test_timescaledb_storage.py -v

# After Task C
pytest tests/unit/test_websdr_config.py -v
```

### Integration Tests
```bash
# After Task D
pytest tests/integration/test_e2e_acquisition.py -v
```

### Performance Tests
```bash
# After Task E
pytest tests/performance/ -v --tb=short
```

### Full Suite
```bash
pytest tests/ -v --cov=src --cov-report=html
```

---

## Code Quality Checklist

For each task, ensure:
- [ ] Functions have docstrings with Args/Returns/Raises
- [ ] Error handling with logging
- [ ] Type hints on all parameters
- [ ] Tests with >80% coverage
- [ ] No hardcoded secrets/passwords
- [ ] Follows project style (black formatting)
- [ ] Integrates with existing patterns

---

## Known Issues & Mitigation

### Issue 1: WebSDR API Variability
- **Risk**: Different receivers may have different response formats
- **Mitigation**: Use mocked responses in tests; real integration in Phase 4+

### Issue 2: Long Acquisition Times
- **Risk**: 10+ second acquisitions may exceed Celery timeouts
- **Mitigation**: Set `task_time_limit=30*60` (30 minutes) in config

### Issue 3: Database Connection Pooling
- **Risk**: Connection leaks if not properly closed
- **Mitigation**: Use context managers; test with connection limit=10

---

## Success Criteria for Phase 3 Completion

‚úÖ **MUST HAVE** (Blocking Phase 4):
1. MinIO storage functional (IQ data files present)
2. TimescaleDB storage functional (measurements queryable)
3. All tests passing (>80% coverage)
4. No CRITICAL errors in logs
5. Celery tasks complete successfully

‚ö†Ô∏è **SHOULD HAVE** (Nice to have):
1. Performance targets validated (<500ms/measurement)
2. Error recovery tested
3. Documentation complete
4. WebSDR configs from database

üî≤ **CAN DEFER** (Phase 4+):
1. Frequency hopping
2. Advanced signal detection
3. Recording session management

---

## Handoff for Next Agent

When transitioning work:

1. **Read these files in order**:
   - `PHASE3_STATUS.md` (current status)
   - `PHASE3_README.md` (architecture & design)
   - `PHASE3_NEXT_STEPS.md` (this file)

2. **Current Code State**:
   - `services/rf-acquisition/src/` - all core components ready
   - `tests/` - comprehensive test fixtures + 18 passing tests
   - `src/tasks/acquire_iq.py` - two tasks have placeholder implementations

3. **Critical Files to Know**:
   - `websdr_fetcher.py` - async concurrent fetch logic (working)
   - `iq_processor.py` - signal processing (working)
   - `acquire_iq.py` - main task; storage functions need implementation
   - `acquisition.py` - FastAPI endpoints (working)

4. **Environment Setup**:
   ```bash
   cd services/rf-acquisition
   pip install -r requirements.txt
   docker-compose up -d
   pytest tests/ -v
   ```

5. **Next Immediate Step**:
   - Implement MinIO storage integration (4-6 hours)
   - Run: `pytest tests/integration/test_minio_storage.py`

---

## Questions & Answers

**Q: Should I mock MinIO/TimescaleDB in tests?**  
A: Partially. Mock for unit tests. Use real containers for integration tests via docker-compose.

**Q: How do I handle WebSDR connection failures?**  
A: Already implemented! Retry logic with exponential backoff. Partial results collected.

**Q: Can Phase 4 start before Phase 3 is complete?**  
A: Not recommended. Phase 4 depends on working storage (MinIO + TimescaleDB).

**Q: Should I implement recording sessions before Phase 3 is done?**  
A: No. Complete Phase 3 first. Recording sessions are Phase 4.

**Q: How do I test without real WebSDRs?**  
A: Use mocked responses. See `tests/fixtures.py` for examples.

---

## Reference Links

- **WebSDR Specs**: See `WEBSDRS.md`
- **Celery Docs**: https://docs.celeryproject.io/
- **SQLAlchemy + TimescaleDB**: https://github.com/timescale/timescaledb-python
- **Boto3 MinIO**: https://docs.min.io/minio/linux/developers/python.html
- **Phase 3 Status**: `PHASE3_STATUS.md`

---

## Emergency Contacts / Escalation

If blocked:
1. Check `PHASE3_STATUS.md` for known limitations
2. Review test failures: `pytest tests/ -v`
3. Check docker-compose: `docker-compose ps`
4. Check Celery worker: `celery -A src.main.celery_app inspect active`
5. Review logs: `docker-compose logs -f rf-acquisition`

---

**Last Update**: October 22, 2025, 19:30 UTC  
**Next Review**: After Task A completion
